#!/bin/sh

### Usage: jft-run -h
### Usage: jft-run -f NODEFILE # file listing the list of available nodes (entries are hostname@type, see traces for available types)
### Usage: jft-run -n N        # number of nodes from the nodefile to use
### Usage: jft-run -r RATE     # limit this client bandwidth to RATE (units are: kbps, mbps, kbit, mbit or bps)
### Usage: jft-run -s FSIZE    # file size in bytes
### Usage: jft-run -b BLKSIZE  # block size in bytes

usage()
{
  perl -ne '/^### Usage:/ && do { s/^### ?//; print }' < $0
  exit 1
}

help()
{
  perl -ne '/^###/ && do { s/^### ?//; print }' < $0
  exit 0
}

# Parse command line arguments
HOSTS= N= RATE= FSIZE= BLKSIZE=
eval set -- $(getopt -n $0 -o hs:n:f:r:s:b: -- ${1+"$@"})
[ $? = 0 ] || usage

for arg; do
  case $arg in
    -n) N="$2"; shift; shift ;;
    -f) [ -f $2 ] && HOSTS=$(cat $2); shift; shift ;;
    -r) RATE="$2"; shift; shift ;;
    -s) FSIZE="$2"; shift; shift ;;
    -b) BLKSIZE="$2"; shift; shift ;;
    -h) help ;;
    --) shift; break ;;
    -*) usage ;;
  esac
done

[ $# = 0 ] || usage

[ X"$HOSTS" = X ] && usage
[ X"$N" = X ] && usage
[ $(echo $HOSTS | wc -w) -lt $N ] && 
  { echo "Do not have enough nodes in the nodefile."; exit 1; }
[ X"$RATE" = X ] && usage
[ X"$FSIZE" = X ] && usage
[ X"$BLKSIZE" = X ] && usage
grid-proxy-info -exists ||
  { echo "Proxy does not exist or expired"; exit 1; }

set -e

# Prepare to run
HOSTS=$(echo $HOSTS | cut -d" " -f-$N)
for host in $HOSTS; do
  h=${host%%@*}; htype=$(echo ${host##*@} | cut -d"/" -f1)
  hmaxbw=${host##*/}
  rsync -zavmH --delete -f '-s .svn' /data/cfg/ $h:/data/cfg/
  (echo "exec 2>&1; set -ex; hostname -f; cd $PWD"
   echo "sudo /etc/init.d/globus-gridftp-server restart"
   echo "mkdir -p /data/state"
   echo "sudo nohup /data/cfg/jft-shaper -i 20 -t $htype -b $hmaxbw &> /data/state/shaper.out &"
   # start the node disconection simulator
  ) | ssh $h bashs -l
done
for host in $HOSTS; do
  h=${host%%@*}; htype=$(echo ${host##*@} | cut -d"/" -f1)
  FILE=/data/state/arquivao
  # Recreates FILE on each host if does not exist or size is not enough
  # Then splits it in BLKSIZE different files due to gridftp limitations to
  # to specify the byte range and to write in parallel to the same file 
  (echo "[ -f $FILE ] && [ \$(stat -c%s $FILE) -ge $FSIZE ] || \\"
   echo "   dd if=/dev/urandom of=$FILE bs=4k count=$(($FSIZE/4096+1))"
   echo "split -a 5 -d -b $BLKSIZE $FILE ${FILE}."
  ) | ssh $h bashs -l &
done
wait

# Used to transfer each block separately
TMPFILES='/data/state/transfered*'

# Do allways clean tmp files upon exit
# also reset the client bandwidth rate to default
trap "sudo /sbin/tc qdisc del dev seth0 root tbf; \
      set -x;
      rm $TMPFILES; \
      for host in \$HOSTS; do \
        ssh \${host%%@*} bashs -c 'echo test; /usr/bin/sudo /usr/bin/killall jft-shaper'; \
      done;" EXIT SIGTERM SIGINT

# Set the client bandwidth
sudo /sbin/tc qdisc add dev seth0 root tbf rate $RATE latency 50ms burst 1540

#
# Run
#
echo "Starting the transfer..."
exec 3>&1 4>&2 # save stdout and stderr

# Make sure it is clean
rm -rf /data/state/transfered*
rm -rf /data/state/out*        # stores each node's screen output
rm -rf /data/state/arquivao    # final destine file
ti=$(date +%s)
c=$(( ($FSIZE+$BLKSIZE-1)/$BLKSIZE )) p=100000
for host in $HOSTS; do
  h=${host%%@*}; htype=$(echo ${host##*@} | cut -d"/" -f1)
  exec &> /data/state/out.$h
  for i in $(seq $p $(($p+($c+$N-1)/$N - 1))); do
    { tii=$(date +%s);
      #echo $i # $(( ($FSIZE - ${i#1}*$BLKSIZE - 1) % $BLKSIZE + 1))
      globus-url-copy \
        gsiftp://$h/data/state/arquivao.${i#1} \
        file:///data/state/transfered.${i#1};

      # debug output entries are: blocknr initial_time endtime
      echo "${i#1} $tii $(date +%s)";
    } &
  done
  p=$(($p+($c+$N-1)/$N))
done
exec 1>&3 2>&4 # restore stdout and stderr
wait # wait all processes to finish

# prints statistics about the transfer
dur=$((`date +%s` - $ti)) # total transfer duration time in seconds
echo "$N $RATE $FSIZE $BLKSIZE $dur" >> /data/state/stats

# reconstructs the file from the transfered blocks
cat /data/state/transfered.* >> /data/state/arquivao

echo "Done."
exit 0
